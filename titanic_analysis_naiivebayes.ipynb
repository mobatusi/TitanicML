{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed data and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.loadtxt('data_preproc_test.txt', delimiter=',')\n",
    "y_train = np.loadtxt('target_train.txt',delimiter=',')\n",
    "X_test = np.loadtxt('data_preproc_test.txt',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes theorem is a famous equation that allows us to make predictions based on data. Here is the classic version of the Bayes theorem:\n",
    "\n",
    "P\n",
    "(\n",
    "A\n",
    "∣\n",
    "B\n",
    ")\n",
    "=\n",
    "P\n",
    "(\n",
    "B\n",
    "∣\n",
    "A\n",
    ")\n",
    "P\n",
    "(\n",
    "A\n",
    ")\n",
    "/\n",
    "P\n",
    "(\n",
    "B\n",
    ")\n",
    "This might be too abstract, so let us replace some of the variables to make it more concrete. In a bayes classifier, we are interested in finding out the class (e.g. male or female, spam or ham) of an observation given the data:\n",
    "\n",
    "p\n",
    "(\n",
    "class\n",
    "∣\n",
    "data\n",
    ")\n",
    "=\n",
    "p\n",
    "(\n",
    "data\n",
    "∣\n",
    "class\n",
    ")\n",
    "∗\n",
    "p\n",
    "(\n",
    "class\n",
    ")\n",
    "/\n",
    "p\n",
    "(\n",
    "data\n",
    ")\n",
    "\n",
    "where:\n",
    "\n",
    "class is a particular class (e.g. male)\n",
    "\n",
    "data is an observation’s data\n",
    "\n",
    "p(class∣data) is called the posterior\n",
    "\n",
    "p(data|class)is called the likelihood\n",
    "\n",
    "p(class) is called the prior\n",
    "\n",
    "p(data) is called the marginal probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gaussian naive bayes is probably the most popular type of bayes classifier. To explain what the name means, let us look at what the bayes equations looks like when we apply our two classes of survival(yes and no) and six feature variables (Pclass, Sex, Age, SibSp,Parch, Embarked):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "posterior(yes) = \\frac{P(yes)p(pclass∣yes)p(sex∣yes)p(age∣yes)p(SibSp∣yes)p(Parch∣yes)p(Embarked∣yes)}{marginal probability}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "posterior(no) = \\frac{P(no)p(pclass∣no)p(sex∣no)p(age∣no)p(SibSp∣no)p(Parch∣no)p(Embarked∣no)}{marginal probability}\n",
    "\\end{equation*}\n",
    "\n",
    "Now let us unpack the top equation a bit:\n",
    "\n",
    "P(yes) is the prior probabilities. It is, as you can see, simply the probability an observation is yes. This is just the number of yes in the dataset divided by the total number of people in the dataset.\n",
    "\n",
    "p(pclass∣no)p(sex∣no)p(age∣no)p(SibSp∣no)p(Parch∣no)p(Embarked∣no) is the likelihood. Notice that we have unpacked person’s data so it is now every feature in the dataset. The “gaussian” and “naive” come from two assumptions present in this likelihood:\n",
    "\n",
    "\t1.If you look each term in the likelihood you will notice that we assume each feature is uncorrelated from each other. That is, foot size is independent of weight or age etc.. This is obviously not true, and is a “naive” assumption - hence the name “naive bayes.”\n",
    "\n",
    "\t2.Second, we assume have that the value of the features (e.g. the age of a survial outcome, the sex of survival outcome) are normally (gaussian) distributed. This means that p(age∣no) is calculated by inputing the required parameters into the probability density function of the normal distribution:\n",
    "\n",
    "p(age∣no)= (1 / √2π * variance of no survival age in the data) * e−(observation’s age − average age of no's in the data)^2 / 2 * variance of no age in the data\n",
    "\n",
    "marginal probability is probably one of the most confusing parts of bayesian approaches. In toy examples (including ours) it is completely possible to calculate the marginal probability. However, in many real-world cases, it is either extremely difficult or impossible to find the value of the marginal probability. This is not as much of a problem for our classifier as you might think. Why? Because we don’t care what the true posterior value is, we only care which class has a the highest posterior value. And because the marginal probability is the same for all classes \n",
    "\n",
    "1) we can ignore the denominator\n",
    "\n",
    "2) calculate only the posterior’s numerator for each class\n",
    "\n",
    "3) pick the largest numerator. That is, we can ignore the posterior’s denominator and make a prediction solely on the relative values of the posterior’s numerator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Priors can be either constants or probability distributions. In our example, this is simply the probability of being a gender. Calculating this is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    }
   ],
   "source": [
    "n_yes = np.count_nonzero(y_train)\n",
    "print(n_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n",
      "424\n",
      "0.4061624649859944\n",
      "0.5938375350140056\n"
     ]
    }
   ],
   "source": [
    "# Total rows\n",
    "total_ppl = np.size(y_train)\n",
    "\n",
    "# Number of yes == 1\n",
    "n_yes = np.count_nonzero(y_train)\n",
    "print(n_yes)\n",
    "\n",
    "# Number of no == 0\n",
    "n_no = total_ppl - n_yes\n",
    "print(n_no)\n",
    "\n",
    "# Number of survived divided by the total rows\n",
    "P_yes = n_yes/total_ppl\n",
    "print(P_yes)\n",
    "\n",
    "# Number of not survived divided by the total rows\n",
    "P_no = n_no/total_ppl\n",
    "print(P_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Likelihood"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "p(age∣no) =  \\frac{1}{2π * variance of no survival age in the data}* e− ^\\frac{(observations age − average age of nos in the data)^2} {2* variance of no age in the data}\n",
    "\\end{equation*} is the likelihood. \n",
    "\n",
    "This means that for each class (e.g. no) and feature (e.g. age) combination we need to calculate the variance and mean value from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train = pd.DataFrame(X_train, columns=['Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X_train['Survial'] = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.012</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.299</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>-0.511</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.012</td>\n",
       "      <td>-1.271</td>\n",
       "      <td>1.181</td>\n",
       "      <td>0.594</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>0.651</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.171</td>\n",
       "      <td>0.787</td>\n",
       "      <td>2.241</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>-0.511</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.012</td>\n",
       "      <td>0.787</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>0.651</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.012</td>\n",
       "      <td>-1.271</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass    Sex    Age  SibSp  Parch  Embarked  Survial\n",
       "0   1.012  0.787  0.299 -0.552 -0.491    -0.511      0.0\n",
       "1   1.012 -1.271  1.181  0.594 -0.491     0.651      1.0\n",
       "2  -0.171  0.787  2.241 -0.552 -0.491    -0.511      1.0\n",
       "3   1.012  0.787 -0.231 -0.552 -0.491     0.651      1.0\n",
       "4   1.012 -1.271 -0.584  0.594  0.744     0.651      0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survial</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>-0.003137</td>\n",
       "      <td>-0.050324</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.049015</td>\n",
       "      <td>-0.012632</td>\n",
       "      <td>0.001647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.079563</td>\n",
       "      <td>-0.010508</td>\n",
       "      <td>-0.077539</td>\n",
       "      <td>0.020492</td>\n",
       "      <td>-0.002625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass       Sex       Age     SibSp     Parch  Embarked\n",
       "Survial                                                            \n",
       "0.0     -0.003137 -0.050324  0.006608  0.049015 -0.012632  0.001647\n",
       "1.0      0.004328  0.079563 -0.010508 -0.077539  0.020492 -0.002625"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the data by gender and calculate the means of each feature\n",
    "data_means = df_X_train.groupby('Survial').mean()\n",
    "\n",
    "# View the values\n",
    "data_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survial</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.040993</td>\n",
       "      <td>1.027136</td>\n",
       "      <td>1.011375</td>\n",
       "      <td>1.105022</td>\n",
       "      <td>1.010458</td>\n",
       "      <td>0.999674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.950415</td>\n",
       "      <td>0.962962</td>\n",
       "      <td>0.997266</td>\n",
       "      <td>0.837866</td>\n",
       "      <td>0.998087</td>\n",
       "      <td>1.015341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass       Sex       Age     SibSp     Parch  Embarked\n",
       "Survial                                                            \n",
       "0.0      1.040993  1.027136  1.011375  1.105022  1.010458  0.999674\n",
       "1.0      0.950415  0.962962  0.997266  0.837866  0.998087  1.015341"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the data by gender and calculate the variance of each feature\n",
    "data_variance = df_X_train.groupby('Survial').var()\n",
    "\n",
    "# View the values\n",
    "data_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means for survived\n",
    "yes_Pclass_mean = data_means['Pclass'][data_variance.index == 1.0].values[0]\n",
    "yes_Sex_mean = data_means['Sex'][data_variance.index == 1.0].values[0]\n",
    "yes_Age_mean = data_means['Age'][data_variance.index == 1.0].values[0]\n",
    "yes_SibSp_mean = data_means['SibSp'][data_variance.index == 1.0].values[0]\n",
    "yes_Parch_mean = data_means['Parch'][data_variance.index == 1.0].values[0]\n",
    "yes_Embarked_mean = data_means['Embarked'][data_variance.index == 1.0].values[0]\n",
    "\n",
    "# Variance for survived\n",
    "yes_Pclass_variance= data_variance['Pclass'][data_variance.index == 1.0].values[0]\n",
    "yes_Sex_variance= data_variance['Sex'][data_variance.index == 1.0].values[0]\n",
    "yes_Age_variance= data_variance['Age'][data_variance.index == 1.0].values[0]\n",
    "yes_SibSp_variance= data_variance['SibSp'][data_variance.index == 1.0].values[0]\n",
    "yes_Parch_variance= data_variance['Parch'][data_variance.index == 1.0].values[0]\n",
    "yes_Embarked_variance= data_variance['Embarked'][data_variance.index == 1.0].values[0]\n",
    "\n",
    "# Means for not survived\n",
    "no_Pclass_mean = data_means['Pclass'][data_variance.index == 0.0].values[0]\n",
    "no_Sex_mean = data_means['Sex'][data_variance.index == 0.0].values[0]\n",
    "no_Age_mean = data_means['Age'][data_variance.index == 0.0].values[0]\n",
    "no_SibSp_mean = data_means['SibSp'][data_variance.index == 0.0].values[0]\n",
    "no_Parch_mean = data_means['Parch'][data_variance.index == 0.0].values[0]\n",
    "no_Embarked_mean = data_means['Embarked'][data_variance.index == 0.0].values[0]\n",
    "\n",
    "# Variance for not survived\n",
    "no_Pclass_variance= data_variance['Pclass'][data_variance.index == 0.0].values[0]\n",
    "no_Sex_variance= data_variance['Sex'][data_variance.index == 0.0].values[0]\n",
    "no_Age_variance= data_variance['Age'][data_variance.index == 0.0].values[0]\n",
    "no_SibSp_variance= data_variance['SibSp'][data_variance.index == 0.0].values[0]\n",
    "no_Parch_variance= data_variance['Parch'][data_variance.index == 0.0].values[0]\n",
    "no_Embarked_variance= data_variance['Embarked'][data_variance.index == 0.0].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to create a function to calculate the probability density of each of the terms of the likelihood (e.g. p(age∣no))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that calculates p(x | y):\n",
    "def p_x_given_y(x, mean_y, variance_y):\n",
    "\n",
    "    # Input the arguments into a probability density function\n",
    "    p = 1/(np.sqrt(2*np.pi*variance_y)) * np.exp((-(x-mean_y)**2)/(2*variance_y))\n",
    "    \n",
    "    # return p\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Bayes Classifier To New Data Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005410936927996303"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numerator of the posterior if the unclassified observation is a male\n",
    "P_yes * \\\n",
    "p_x_given_y(df_X_train['Pclass'][0], yes_Pclass_mean, yes_Pclass_variance) * \\\n",
    "p_x_given_y(df_X_train['Sex'][0], yes_Sex_mean, yes_Sex_variance) * \\\n",
    "p_x_given_y(df_X_train['Age'][0], yes_Age_mean, yes_Age_variance) * \\\n",
    "p_x_given_y(df_X_train['SibSp'][0], yes_SibSp_mean, yes_SibSp_variance) * \\\n",
    "p_x_given_y(df_X_train['Parch'][0], yes_Parch_mean, yes_Parch_variance) * \\\n",
    "p_x_given_y(df_X_train['Embarked'][0], yes_Embarked_mean, yes_Embarked_variance) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006018346494434054"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numerator of the posterior if the unclassified observation is a female\n",
    "P_no * \\\n",
    "p_x_given_y(df_X_train['Pclass'][0], no_Pclass_mean, no_Pclass_variance) * \\\n",
    "p_x_given_y(df_X_train['Sex'][0], no_Sex_mean, no_Sex_variance) * \\\n",
    "p_x_given_y(df_X_train['Age'][0], no_Age_mean, no_Age_variance) * \\\n",
    "p_x_given_y(df_X_train['SibSp'][0], no_SibSp_mean, no_SibSp_variance) * \\\n",
    "p_x_given_y(df_X_train['Parch'][0], no_Parch_mean, no_Parch_variance) * \\\n",
    "p_x_given_y(df_X_train['Embarked'][0], no_Embarked_mean, no_Embarked_variance) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create support vector classifier\n",
    "svc = LinearSVC(C=1.0)\n",
    "\n",
    "# Train model\n",
    "model = svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Observation To Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the learner to the new, unclassified observation.\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Predicted Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# View predicted class probabilities for the three classes\n",
    "svc.predict(X_test)\n",
    "print(np.shape(svc.predict(X_test)))\n",
    "print(svc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View The Model’s Score\n",
    "How good is our trained model compared to our training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model is 79.13% accurate!\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model is %.2f%% accurate!\" % (model.score(X_train, y_train)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create standardizer\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# Create SVM classifier\n",
    "svm = svc\n",
    "\n",
    "# Create a pipeline that standardizes, then runs logistic regression\n",
    "pipeline = make_pipeline(standardizer, svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline, # Pipeline\n",
    "                             X_train, # Feature matrix\n",
    "                             y_train, # Target vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring=\"accuracy\", # Loss function\n",
    "                             n_jobs=-1) # Use all CPU scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77777778, 0.73611111, 0.79166667, 0.80555556, 0.71830986,\n",
       "       0.8028169 , 0.78873239, 0.71830986, 0.87323944, 0.78873239])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Mean Performance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7801251956181534"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate mean\n",
    "cv_results.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
